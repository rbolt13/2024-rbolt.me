writer.writerow({'Title': title, 'Artist': artist, 'Year': year, 'Label': label, 'Genre': genre})
?identity()
collection = discogs.identity().collection_folders[0]
collection
for release in collection:
print(release.release.title, release.release.artists[0].name, release.release.year)
].releases
].releases
for release in collection:
print(release.release.title, release.release.artists[0].name, release.release.year)
import discogs_client
# Authenticate with Discogs API
discogs = discogs_client.Client('rbolt13', user_token='IEdbUGdVBZgbdmSCWYYCSSUOlQDUTPGtuZHGtnAI')
# Fetch collection data
collection = discogs.identity().collection_folders[0].releases
# Process collection data
for release in collection:
print(release.release.title, release.release.artists[0].name, release.release.year)
import discogs_client
# Authenticate with Discogs API
discogs = discogs_client.Client('rbolt13', user_token='IEdbUGdVBZgbdmSCWYYCSSUOlQDUTPGtuZHGtnAI')
# Fetch collection data
collection = discogs.identity().collection_folders[0]
# Process collection data
for release in collection:
print(release.release.title, release.release.artists[0].name, release.release.year)
import discogs_client
# Authenticate with Discogs API
discogs = discogs_client.Client('rbolt13', user_token='IEdbUGdVBZgbdmSCWYYCSSUOlQDUTPGtuZHGtnAI')
# Fetch collection data
collection = discogs.identity().collection_folders[0].releases
# Process collection data
for release in collection:
print(release.release.title, release.release.artists[0].name, release.release.year, release.release.rating)
import discogs_client
# Authenticate with Discogs API
discogs = discogs_client.Client('rbolt13', user_token='IEdbUGdVBZgbdmSCWYYCSSUOlQDUTPGtuZHGtnAI')
# Fetch collection data
collection = discogs.identity().collection_folders[0].releases
# Process collection data
for release in collection:
print(release.release.title, release.release.artists[0].name, release.release.year, release.release.genre)
import discogs_client
# Authenticate with Discogs API
discogs = discogs_client.Client('rbolt13', user_token='IEdbUGdVBZgbdmSCWYYCSSUOlQDUTPGtuZHGtnAI')
# Fetch collection data
collection = discogs.identity().collection_folders[0].releases
# Process collection data
for release in collection:
print(release.release.title, release.release.artists[0].name, release.release.year)
library(readr)
library(dplyr)
# Load Data
cereals <- readr::read_csv("../../../../data/cereal.csv")
library(janitor)
# Load Data
cereals <- readr::read_csv("../../../../data/cereal.csv", ) |>
janitor::clean_names() |>
dplyr::mutate(shelf = factor(shelf, ordered = TRUE)) |>
dplyr::mutate(c("manufacturer", "type"), as.factor)
# Load Packages
library(skimr)
library(readr)
library(dplyr)
library(janitor)
# Load Data
cereals <- readr::read_csv("../../../../data/cereal.csv", ) |>
janitor::clean_names() |>
mutate(shelf = factor(shelf, ordered=TRUE)) |>
mutate(across(c("manufacturer", "type"), as.factor))
# Load Packages
library(skimr)
library(readr)
library(dplyr)
library(janitor)
# Load Data
cereals <- readr::read_csv("../../../../data/cereal.csv", ) |>
janitor::clean_names() |>
dplyr::mutate(shelf = factor(shelf, ordered = TRUE)) |>
dplyr::mutate(c("manufacturer", "type"), as.factor))
# Load Packages
library(skimr)
library(readr)
library(dplyr)
library(janitor)
# Load Data
cereals <- readr::read_csv("../../../../data/cereal.csv", ) |>
janitor::clean_names() |>
dplyr::mutate(shelf = factor(shelf, ordered = TRUE)) |>
dplyr::mutate(c("manufacturer", "type"), as.factor)
# Load Data
cereals <- readr::read_csv("../../../../data/cereal.csv") |>
janitor::clean_names() |>
dplyr::mutate(shelf = factor(shelf, ordered = TRUE)) |>
dplyr::mutate(across(c("manufacturer", "type"), as.factor))
# Load Data
cereals <- readr::read_csv("../../../../data/cereal.csv") |>
janitor::clean_names() |>
dplyr::mutate(shelf = factor(shelf, ordered = TRUE)) |>
dplyr::mutate(across(c("manufacturer", "type"), as.factor))
cereals
# Load Packages
library(skimr)
library(readr)
library(dplyr)
library(janitor)
# Load Data
cereals <- readr::read_csv("../../../../data/cereal.csv") |>
janitor::clean_names() |>
dplyr::mutate(shelf = factor(shelf, ordered = TRUE)) |>
dplyr::mutate(across(c("mfc", "type"), as.factor))
cereals
# Load Data
cereals <- readr::read_csv("../../../../data/cereal.csv") |>
janitor::clean_names() |>
dplyr::mutate(shelf = factor(shelf, ordered = TRUE)) |>
dplyr::mutate(across(c("mfr", "type"), as.factor))
?clean_names()
summary(cereals)
skim_output <- skimr::skim(cereals)
summary(skim_output)
skimr::yank(skim_output, "character")
?yank()
skimr::yank(skim_output, "factor")
cearals <- cearals |>
mutate(manufacturer = forcats::fct_recode(
manufacturer, !!!manu_labels))
manu_labels <- c("American Home"="A",
"General Mills"="G",
"Kelloggs"="K",
"Nabisco" = "N",
"Post" = "P",
"Quaker Oats" = "Q",
"Ralston Purina" = "R")
cearals <- cearals |>
mutate(manufacturer = forcats::fct_recode(
manufacturer, !!!manu_labels))
#| output: false
# Load Data
cereals <- readr::read_csv("../../../../data/cereal.csv") |>
# clean names by converting to lowercase, replace spaces
# with underscore and removes special characters
janitor::clean_names() |>
# make shelf an ordered factor
dplyr::mutate(shelf = factor(shelf, ordered = TRUE)) |>
# convert mfr and type columns to categorical data
dplyr::mutate(across(c("mfr", "type"), as.factor))
manu_labels <- c("American Home"="A",
"General Mills"="G",
"Kelloggs"="K",
"Nabisco" = "N",
"Post" = "P",
"Quaker Oats" = "Q",
"Ralston Purina" = "R")
cereals <- cereals |>
mutate(manufacturer = forcats::fct_recode(
manufacturer, !!!manu_labels))
manu_labels <- c("American Home"="A",
"General Mills"="G",
"Kelloggs"="K",
"Nabisco" = "N",
"Post" = "P",
"Quaker Oats" = "Q",
"Ralston Purina" = "R")
cereals <- cereals |>
mutate(mfr = forcats::fct_recode(mfr, !!!manu_labels))
cereals
cereals |>
janitor::tabyl(shelf)
?mutate()
#| output: false
manu_labels <- c("American Home"="A",
"General Mills"="G",
"Kelloggs"="K",
"Nabisco" = "N",
"Post" = "P",
"Quaker Oats" = "Q",
"Ralston Purina" = "R")
cereals <- cereals |>
dplyr::mutate(mfr = forcats::fct_recode(mfr, !!!manu_labels))
#| output: false
manu_labels <- c("American Home"="A",
"General Mills"="G",
"Kelloggs"="K",
"Nabisco" = "N",
"Post" = "P",
"Quaker Oats" = "Q",
"Ralston Purina" = "R")
cereals <- cereals |>
dplyr::mutate(mfr = forcats::fct_recode(mfr, !!!manu_labels))
cereals |>
janitor::tabyl(manufacturer, type) |>
janitor::adorn_percentages(denominator = "row") |>
janitor::adorn_pct_formatting() |>
janitor::adorn_ns() |>
knitr::kable()
cereals |>
janitor::tabyl(mfr, type) |>
janitor::adorn_percentages(denominator = "row") |>
janitor::adorn_pct_formatting() |>
janitor::adorn_ns() |>
knitr::kable()
?tabyl()
?adorn_percentages()
?kable()
cereals |>
# Create frequency table of manufacturers by shelf
janitor::tabyl(mfr, shelf) |>
# Calculate percentages based on shelf total
janitor::adorn_percentages(denominator="row") |>
# Add totals
janitor::adorn_ns() |>
# Nicely format table
knitr::kable()
cereals |>
# Create frequency table of manufacturers by shelf
janitor::tabyl(mfr, shelf) |>
# Calculate percentages based on shelf total
janitor::adorn_percentages(denominator="row") |>
# Add totals
janitor::adorn_ns() |>
mutate_all(~if_else(is.numeric(.), round(., 2), as.character(.))) |>
# Nicely format table
knitr::kable()
cereals |>
# Create frequency table of manufacturers by shelf
janitor::tabyl(mfr, shelf) |>
# Calculate percentages based on shelf total
janitor::adorn_percentages(denominator="row") |>
# Add totals
janitor::adorn_ns() |>
# Nicely format table
knitr::kable(digits = 2)
cereals |>
# Create frequency table of manufacturers by shelf
janitor::tabyl(mfr, shelf) |>
# Calculate percentages based on shelf total
janitor::adorn_percentages(denominator="row") |>
# Add totals
janitor::adorn_ns() |>
mutate_if(is.numeric, ~format_number(., digits = 2)) |>
# Nicely format table
knitr::kable()
cereals |>
# Create frequency table of manufacturers by shelf
janitor::tabyl(mfr, shelf) |>
# Calculate percentages based on shelf total
janitor::adorn_percentages(denominator="row") |>
# Add totals
janitor::adorn_ns() |>
# Nicely format table
knitr::kable()
cereals |>
# Create frequency table of manufacturers by shelf
janitor::tabyl(mfr, shelf) |>
# Calculate percentages based on shelf total
janitor::adorn_percentages(denominator="row") |>
janitor::adorn_pct_formatting() |>
# Add totals
janitor::adorn_ns() |>
# Nicely format table
knitr::kable()
write.csv(m_c, here::here("../../../../data/mascots.csv"))
library(rvest)
mascots <- read_html("https://www.whiteclouds.com/listicles/268-cereal-mascots/")
mascot_list <- mascots |> html_elements("p") |>
html_elements("strong") |>
html_text2() |>
stringr::str_replace("^[0-9]+\\.\\s", "")
m_l <- length(mascot_list)
mascot_list <- mascot_list[1:(m_l-3)] |>
stringr::str_split(" – ", n=2)
mascots <- unlist(purrr::map(mascot_list, ~.x[[1]]))
mascot_cereal <- unlist(purrr::map(mascot_list, ~.x[[2]]))
m_c <- data.frame(mascot=mascots, name=mascot_cereal)
write.csv(m_c, here::here("../../../../data/mascots.csv"))
# Load Data
m_c <- readr::read_csv("../../../../data/mascots.csv")
# Load Data
m_c <- readr::read_csv("../../../../data/mascots.csv",
row.names = NULL)
m_c
# Load Data
m_c <- readr::read_csv("../../../../data/mascots.csv")
# Clean cereal names
m_c <- m_c |>
mutate(name=stringr::str_replace(name,"Cap’n Crunch cereals", "Cap'n'Crunch")) |>
mutate(name=stringr::str_replace(name, "Count Chocula cereal", "Count Chocula")) |>
mutate(name=stringr::str_replace(name, "Honey Smacks", "Smacks")) |>
mutate(name=stringr::str_replace(name, "Mini-Wheats", "Frosted Mini-Wheats"))
?read_csv()
# Load Data
m_c <- readr::read_csv("../../../../data/mascots.csv",
row_names = NULL)
?read.csv()
# Load Data
m_c <- utils::read.csv("../../../../data/mascots.csv",
row.names = NULL)
# Clean cereal names
m_c <- m_c |>
mutate(name=stringr::str_replace(name,"Cap’n Crunch cereals", "Cap'n'Crunch")) |>
mutate(name=stringr::str_replace(name, "Count Chocula cereal", "Count Chocula")) |>
mutate(name=stringr::str_replace(name, "Honey Smacks", "Smacks")) |>
mutate(name=stringr::str_replace(name, "Mini-Wheats", "Frosted Mini-Wheats"))
?mutate()
library(dplyr)
# Load Data
m_c <- utils::read.csv("../../../../data/mascots.csv",
row.names = NULL)
# Clean cereal names
m_c <- m_c |>
mutate(name=stringr::str_replace(name,"Cap’n Crunch cereals", "Cap'n'Crunch")) |>
mutate(name=stringr::str_replace(name, "Count Chocula cereal", "Count Chocula")) |>
mutate(name=stringr::str_replace(name, "Honey Smacks", "Smacks")) |>
mutate(name=stringr::str_replace(name, "Mini-Wheats", "Frosted Mini-Wheats"))
# join with cereals data
mascot_count <- cereals |>
left_join(y=m_c, by="name") |>
mutate(has_mascot = ifelse(is.na(mascot), "No", "Yes"))
# check dimension
dim(mascot_count)
mascot_count |>
# Filter to second shelf
dplyr::filter(shelf==2) |>
# Select only name, manufacturer, mascot, and has_mascot
select(name, mfr, mascot, has_mascot) |>
# Arrange by mascot
arrange(mascot) |>
# Nicely format table
knitr::kable()
mascot_count |>
# Select name, shelf, and has_mascot columns
select(name, shelf, has_mascot) |>
# Remove the duplicate rows
distinct() |>
# Create crosstable of shelfs by has_mascot
janitor::tabyl(shelf, has_mascot) |>
# Calculate percentage based on Yes or No to having a mascot
janitor::adorn_percentages() |>
# Format percentages
janitor::adorn_pct_formatting() |>
# Add totals
janitor::adorn_ns() |>
# Nicely format table
knitr::kable()
mascot_count |>
# Select name, manufacturer, and has_mascot
select(name, mfr, has_mascot) |>
# Remove the duplicate rows
distinct() |>
# Create crosstable of shelfs by has_mascot
janitor::tabyl(mfr, has_mascot) |>
# Calculate percentages based on column totals
janitor::adorn_percentages(denominator = "col") |>
# Format percentages
janitor::adorn_pct_formatting() |>
# Add totals
janitor::adorn_ns() |>
# Nicely format table
knitr::kable()
library(ggplot2)
#| output: false
# Install Package
# install.packages("skimr")
# Load Packages
library(skimr)
library(readr)
library(dplyr)
library(janitor)
library(ggplot2)
#| output: false
# Load Data
cereals <- readr::read_csv("../../../../data/cereal.csv") |>
# clean names by converting to lowercase, replace spaces
# with underscore and removes special characters
janitor::clean_names() |>
# make shelf an ordered factor
dplyr::mutate(shelf = factor(shelf, ordered = TRUE)) |>
# convert mfr and type columns to categorical data
dplyr::mutate(across(c("mfr", "type"), as.factor))
summary(cereals)
skim_output <- skimr::skim(cereals)
summary(skim_output)
skimr::yank(skim_output, "character")
skimr::yank(skim_output, "factor")
skimr::yank(skim_output, "numeric")
x <- skimr::yank(skim_output, "numeric")
ggsave("img.pgn", x)
x <- skimr::yank(skim_output, "numeric")
ggsave("img.png", x)
x <- skimr::yank(skim_output, "numeric")
library(gridExtra)
table_grob <- tableGrob(x)
# Convert tableGrob to a ggplot object
table_plot <- as_ggplot(table_grob)
# Convert tableGrob to a ggplot object
table_plot <- ggplot(table_grob)
install.packages("rpart")
install.packages("rpart.plot")
#### Load Packages ####
# tidyverse: A collection of data-related packages.
# rpart:
# rpart.plot:
base::library(tidyverse)
base::library(rpart)
base::library(rpart.plot)
#### Load Data ####
team_results <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-03-26/team-results.csv')
public_picks <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-03-26/public-picks.csv')
team_results$F4PERCENT <- as.numeric(gsub("%", "", team_results$F4PERCENT)) / 100
head(team_results)
model <- rpart(WINPERCENT ~ PAKE + PASE + GAMES, data = team_results, method = "anova")
rpart.plot(model)
head(public_picks)
this_years_teams <- public_picks |>
filter(YEAR == "2024")
this_years_teams
# You need to add this year's teams' PAKE and GAMES to the data frame
# For this example, let's assume that 'this_years_teams' is a data frame containing this year's teams' data
predictions <- predict(model, newdata = this_years_teams)
# You need to add this year's teams' PAKE and GAMES to the data frame
# For this example, let's assume that 'this_years_teams' is a data frame containing this year's teams' data
predictions <- predict(model, newdata = this_years_teams)
team_results
?join_by()
this_years_teams <- public_picks |>
filter(YEAR == "2024") |>
merge(team_results,
by = "TEAM")
this_years_teams
# You need to add this year's teams' PAKE and GAMES to the data frame
# For this example, let's assume that 'this_years_teams' is a data frame containing this year's teams' data
predictions <- predict(model, newdata = this_years_teams)
# First, let's assume that you have a way to link the two datasets. Perhaps they both have a TEAMID for this year's teams.
# You'll need to ensure that 'this_years_teams' has a 'TEAMID' column that corresponds to the 'TEAMNO' column in 'public_picks'.
# Merge the predictions with the public picks data based on the team identifier
combined_predictions <- left_join(this_years_teams, public_picks, by = c("TEAMID" = "TEAMNO"))
# Then you would calculate the weighted average of your model's prediction and the public picks
combined_predictions <- combined_predictions %>%
mutate(WeightedWinPercent = (predictions + R64) / 2)  # Replace R64 with the appropriate round's public pick
combined_predictions
# First, let's assume that you have a way to link the two datasets. Perhaps they both have a TEAMID for this year's teams.
# You'll need to ensure that 'this_years_teams' has a 'TEAMID' column that corresponds to the 'TEAMNO' column in 'public_picks'.
# Merge the predictions with the public picks data based on the team identifier
combined_predictions <- left_join(this_years_teams, public_picks, by = c("TEAMID" = "TEAMNO"))
# Then you would calculate the weighted average of your model's prediction and the public picks
combined_predictions <- combined_predictions %>%
mutate(WeightedWinPercent = (predictions + R64.x) / 2)  # Replace R64 with the appropriate round's public pick
# First, let's assume that you have a way to link the two datasets. Perhaps they both have a TEAMID for this year's teams.
# You'll need to ensure that 'this_years_teams' has a 'TEAMID' column that corresponds to the 'TEAMNO' column in 'public_picks'.
# Merge the predictions with the public picks data based on the team identifier
combined_predictions <- left_join(this_years_teams, public_picks, by = c("TEAMID" = "TEAMNO"))
# Then you would calculate the weighted average of your model's prediction and the public picks
combined_predictions <- combined_predictions %>%
mutate(WeightedWinPercent = (predictions + R64) / 2)  # Replace R64 with the appropriate round's public pick
# Assuming you've already created 'this_years_teams' with the appropriate data
# Predict the winning percentage
predictions <- predict(model, newdata = this_years_teams)
# Add the predictions as a new column to 'this_years_teams'
this_years_teams$PredictedWinPercent <- predictions
# Merge with the public picks
# Ensure that the 'TEAMID' from 'this_years_teams' corresponds to the 'TEAMNO' in 'public_picks' for this year's data
combined_predictions <- merge(this_years_teams, public_picks, by.x = "TEAMID", by.y = "TEAMNO")
# Now, before calculating the weighted average, ensure that R64 is numeric and not a factor or character
combined_predictions$R64 <- as.numeric(as.character(combined_predictions$R64))
# Calculate the weighted average of your model's prediction and the public picks for the Round of 64
combined_predictions$WeightedWinPercent <- (combined_predictions$PredictedWinPercent + combined_predictions$R64) / 2
# Check the results
head(combined_predictions)
# Assuming you've already created 'this_years_teams' with the appropriate data
# Predict the winning percentage
predictions <- predict(model, newdata = this_years_teams)
# Add the predictions as a new column to 'this_years_teams'
this_years_teams$PredictedWinPercent <- predictions
# Merge with the public picks
# Ensure that the 'TEAMID' from 'this_years_teams' corresponds to the 'TEAMNO' in 'public_picks' for this year's data
combined_predictions <- merge(this_years_teams, public_picks, by.x = "TEAM", by.y = "TEAM")
# Now, before calculating the weighted average, ensure that R64 is numeric and not a factor or character
combined_predictions$R64 <- as.numeric(as.character(combined_predictions$R64))
# Calculate the weighted average of your model's prediction and the public picks for the Round of 64
combined_predictions$WeightedWinPercent <- (combined_predictions$PredictedWinPercent + combined_predictions$R64) / 2
# Check the results
head(combined_predictions)
# Make sure both data frames are using the same case for TEAM names, if used as keys
this_years_teams$TEAM <- toupper(this_years_teams$TEAM)
public_picks$TEAM <- toupper(public_picks$TEAM)
# Assuming you've already created 'this_years_teams' with the appropriate data
# Predict the winning percentage
predictions <- predict(model, newdata = this_years_teams)
# Add the predictions as a new column to 'this_years_teams'
this_years_teams$PredictedWinPercent <- predictions
# Since the keys seem to be 'TEAMNO' and 'YEAR', ensure that the keys match and have the same names in both data frames
# You might need to rename columns in your data frames to match
# Then, merge using 'TEAMNO' and 'YEAR'
combined_predictions <- merge(this_years_teams, public_picks, by = c("TEAMNO", "YEAR"))
# Assuming the merge worked and we have non-zero rows now, continue with the previous steps:
# Convert the pick percentages to numeric
public_picks_columns <- c("R64", "R32", "S16", "E8", "F4", "FINALS")
combined_predictions[public_picks_columns] <- lapply(combined_predictions[public_picks_columns], function(x) as.numeric(gsub("%", "", x)) / 100)
install.packages("partykit")
install.packages("ggparty")
library(partykit)
library(ggparty)
# First, convert your rpart object to a party object
party_model <- as.party(model)
# Now, use ggparty to plot
ggplot(party_model) +
geom_edge(aes(start_cap = ifelse(id == 1, "none", "circle"))) +
geom_edge_label(aes(label = splitvar)) +
geom_node_label(aes(label = paste0("Node ", id, "\n",
"n = ", nodesize, "\n",
"Win Percentage: ", round(prediction, 2))))
